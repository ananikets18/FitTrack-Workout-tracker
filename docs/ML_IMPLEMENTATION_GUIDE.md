# ü§ñ Machine Learning Implementation Guide

## Complete Step-by-Step Guide to Add ML to FitTrack

---

## üìã **Overview**

This guide shows you how to add **real machine learning models** to FitTrack using:
- **Random Forest** models (scikit-learn)
- **TensorFlow.js** for browser inference
- **Python** for model training
- **React** for UI integration

---

## üéØ **3 ML Models We're Building**

### **1. Workout Success Predictor** üéØ
- **Predicts**: Will the user complete their planned workout?
- **Accuracy Target**: 80-85%
- **Input**: Sleep, nutrition, fatigue, readiness
- **Output**: Probability (0-100%)

### **2. Recovery Time Predictor** ‚è±Ô∏è
- **Predicts**: Personalized recovery time for each muscle
- **Accuracy Target**: ¬±0.5 days
- **Input**: Workout volume, intensity, sleep, nutrition
- **Output**: Days until recovered

### **3. Weight Progression Predictor** üí™
- **Predicts**: Optimal weight increase for each exercise
- **Accuracy Target**: ¬±1kg
- **Input**: Previous weight, reps, form quality
- **Output**: Recommended increase (kg)

---

## üìÖ **Implementation Timeline**

### **Phase 1: Data Collection** (Months 1-3)
**Goal**: Collect 1,000-10,000 training samples

**Steps**:
1. ‚úÖ Run database migration (already created)
2. ‚úÖ Integrate data collector into app
3. ‚è≥ Wait for users to generate data
4. ‚è≥ Monitor data quality

### **Phase 2: Model Training** (Month 4)
**Goal**: Train and validate ML models

**Steps**:
1. Export data from Supabase
2. Run Python training script
3. Evaluate model performance
4. Convert models to TensorFlow.js

### **Phase 3: Deployment** (Month 5)
**Goal**: Deploy models to production

**Steps**:
1. Upload models to CDN
2. Integrate inference service
3. A/B test ML vs rule-based
4. Monitor performance

---

## üöÄ **Step-by-Step Implementation**

### **STEP 1: Run Database Migration**

```bash
# Open Supabase SQL Editor
# Copy and paste the contents of:
supabase/migrations/20260118_ml_training_tables.sql

# This creates 3 tables:
# - ml_training_data (workout completion)
# - ml_recovery_data (recovery times)
# - ml_progression_data (weight increases)
```

---

### **STEP 2: Integrate Data Collection**

Update your workout completion handler to log ML data:

```javascript
// In src/pages/WorkoutLog.jsx or wherever workouts are saved

import { logWorkoutCompletionData } from '../utils/mlDataCollector';
import { useSleep } from '../context/SleepContext';
import { useNutrition } from '../context/NutritionContext';

const handleCompleteWorkout = async () => {
  // ... existing workout save logic ...

  // NEW: Log data for ML training
  const lastSleep = sleepLogs[0];
  const todayNutrition = getDailyTotals(nutritionLogs, today);
  
  await logWorkoutCompletionData({
    // Features
    sleepHours: lastSleep?.hours_slept || 7,
    sleepQuality: lastSleep?.quality || 3,
    caloriesConsumed: todayNutrition.calories,
    proteinConsumed: todayNutrition.protein,
    fatigueScore: calculateFatigueScore(workouts, sleepLogs),
    daysSinceLastRest: getDaysSinceRest(workouts),
    plannedVolume: calculatePlannedVolume(workout),
    readinessScore: calculateReadinessScore(workouts, sleepLogs),
    injuryRiskScore: assessInjuryRisk(workouts, sleepLogs).overallRisk,
    
    // Targets
    workoutCompleted: true,  // They completed it!
    completionPercentage: calculateCompletionPercentage(workout),
    perceivedDifficulty: perceivedDifficulty, // Ask user 1-10
    
    // Metadata
    userId: user.id,
    workoutId: workout.id,
    timestamp: new Date().toISOString()
  });
};
```

**Add a quick feedback modal after workout:**

```javascript
// Ask user how the workout felt
<Modal show={showFeedback} onClose={() => setShowFeedback(false)}>
  <h3>How was your workout?</h3>
  <p>Rate difficulty (1-10):</p>
  <input 
    type="range" 
    min="1" 
    max="10" 
    value={perceivedDifficulty}
    onChange={(e) => setPerceivedDifficulty(e.target.value)}
  />
  <p>Current: {perceivedDifficulty}/10</p>
  <button onClick={submitFeedback}>Submit</button>
</Modal>
```

---

### **STEP 3: Monitor Data Collection**

Create an admin dashboard to monitor ML data:

```javascript
// src/pages/MLDataDashboard.jsx

import { getMLDataStats } from '../utils/mlDataCollector';

const MLDataDashboard = () => {
  const [stats, setStats] = useState(null);

  useEffect(() => {
    const loadStats = async () => {
      const { stats } = await getMLDataStats();
      setStats(stats);
    };
    loadStats();
  }, []);

  return (
    <div>
      <h2>ML Training Data Status</h2>
      
      <div className="progress-card">
        <h3>Workout Completion Data</h3>
        <p>{stats?.ml_training_data || 0} / 10,000 samples</p>
        <ProgressBar value={stats?.progress || 0} />
        
        {stats?.readyForTraining ? (
          <p>‚úÖ Ready for basic training (1,000+ samples)</p>
        ) : (
          <p>‚è≥ Collecting data... ({stats?.ml_training_data || 0}/1,000)</p>
        )}
        
        {stats?.optimalDataReached && (
          <p>üéâ Optimal data reached! Ready for high-accuracy models</p>
        )}
      </div>

      <div className="progress-card">
        <h3>Recovery Data</h3>
        <p>{stats?.ml_recovery_data || 0} samples</p>
      </div>

      <div className="progress-card">
        <h3>Progression Data</h3>
        <p>{stats?.ml_progression_data || 0} samples</p>
      </div>
    </div>
  );
};
```

---

### **STEP 4: Export Data for Training**

After 3-6 months of data collection:

```javascript
// Export data to CSV
import { exportTrainingData } from '../utils/mlDataCollector';

const exportData = async () => {
  const { csv } = await exportTrainingData('workout_completion', 10000);
  
  // Download CSV file
  const blob = new Blob([csv], { type: 'text/csv' });
  const url = window.URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'workout_completion_data.csv';
  a.click();
};
```

---

### **STEP 5: Train ML Models**

Install Python dependencies:

```bash
pip install scikit-learn pandas numpy joblib tensorflow
```

Train models:

```bash
# Train workout success predictor
python ml/train_models.py --model workout_success --data workout_completion_data.csv

# Train recovery time predictor
python ml/train_models.py --model recovery_time --data recovery_data.csv

# Train weight progression predictor
python ml/train_models.py --model weight_progression --data progression_data.csv

# Or train all at once
python ml/train_models.py --model all --data all_data.csv
```

**Expected Output:**
```
==================================================
WORKOUT SUCCESS PREDICTOR - Training Results
==================================================
Accuracy: 84.23%
Training samples: 8000
Test samples: 2000

Classification Report:
              precision    recall  f1-score
Failed            0.82      0.79      0.80
Completed         0.86      0.88      0.87

Feature Importance:
         feature  importance
   readiness_score      0.28
     fatigue_score      0.22
      sleep_hours       0.18
    sleep_quality       0.15
...

‚úÖ Model saved to models/workout_success_model.pkl
```

---

### **STEP 6: Convert Models to TensorFlow.js**

```python
# Convert scikit-learn model to TensorFlow.js format

import tensorflowjs as tfjs
from sklearn.ensemble import RandomForestClassifier
import joblib

# Load trained model
model_data = joblib.load('models/workout_success_model.pkl')
model = model_data['model']

# Convert to TensorFlow format (requires additional steps)
# This is simplified - actual conversion is more complex

# Alternative: Use ONNX format
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

initial_type = [('float_input', FloatTensorType([None, 9]))]
onx = convert_sklearn(model, initial_types=initial_type)

with open("models/workout_success_model.onnx", "wb") as f:
    f.write(onx.SerializeToString())
```

**Or use a simpler approach: API endpoint**

---

### **STEP 7: Deploy Models (Option A: API Endpoint)**

Create a Python Flask API:

```python
# ml/api.py

from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import numpy as np

app = Flask(__name__)
CORS(app)

# Load models
models = {
    'workout_success': joblib.load('models/workout_success_model.pkl'),
    'recovery_time': joblib.load('models/recovery_time_model.pkl'),
    'weight_progression': joblib.load('models/weight_progression_model.pkl')
}

@app.route('/predict/workout-success', methods=['POST'])
def predict_workout_success():
    data = request.json
    features = [
        data['sleepHours'],
        data['sleepQuality'],
        data['calories'],
        data['protein'],
        data['fatigueScore'],
        data['daysSinceRest'],
        data['plannedVolume'],
        data['readinessScore'],
        data['injuryRiskScore']
    ]
    
    model = models['workout_success']['model']
    scaler = models['workout_success']['scaler']
    
    features_scaled = scaler.transform([features])
    probability = model.predict_proba(features_scaled)[0][1]
    
    return jsonify({
        'willComplete': probability > 0.5,
        'probability': float(probability),
        'confidence': abs(probability - 0.5) * 2
    })

@app.route('/predict/recovery-time', methods=['POST'])
def predict_recovery_time():
    # Similar implementation
    pass

@app.route('/predict/weight-progression', methods=['POST'])
def predict_weight_progression():
    # Similar implementation
    pass

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

Deploy to:
- **Heroku** (free tier)
- **Railway** (easy deployment)
- **AWS Lambda** (serverless)
- **Google Cloud Run** (containerized)

---

### **STEP 8: Integrate with React App**

Update the inference service to use API:

```javascript
// src/utils/mlInferenceService.js

const API_URL = process.env.REACT_APP_ML_API_URL || 'http://localhost:5000';

export const predictWorkoutSuccess = async (features) => {
  try {
    const response = await fetch(`${API_URL}/predict/workout-success`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(features)
    });
    
    const prediction = await response.json();
    return prediction;
  } catch (error) {
    console.error('ML API Error:', error);
    // Fallback to rule-based prediction
    return fallbackPrediction('workout_success', features);
  }
};
```

---

### **STEP 9: Use ML Predictions in UI**

```javascript
// src/pages/Home.jsx

import { predictWorkoutSuccess } from '../utils/mlInferenceService';

const Home = () => {
  const [mlPrediction, setMlPrediction] = useState(null);

  useEffect(() => {
    const getPrediction = async () => {
      const features = {
        sleepHours: lastSleep?.hours_slept || 7,
        sleepQuality: lastSleep?.quality || 3,
        calories: todayNutrition.calories,
        protein: todayNutrition.protein,
        fatigueScore: calculateFatigueScore(workouts, sleepLogs),
        daysSinceRest: getDaysSinceRest(workouts),
        plannedVolume: calculatePlannedVolume(recommendedWorkout),
        readinessScore: calculateReadinessScore(workouts, sleepLogs),
        injuryRiskScore: assessInjuryRisk(workouts, sleepLogs).overallRisk
      };

      const prediction = await predictWorkoutSuccess(features);
      setMlPrediction(prediction);
    };

    if (recommendedWorkout) {
      getPrediction();
    }
  }, [recommendedWorkout, sleepLogs, nutritionLogs]);

  return (
    <div>
      {/* ML Prediction Card */}
      {mlPrediction && (
        <Card className={mlPrediction.willComplete ? 'success' : 'warning'}>
          <h3>ü§ñ AI Prediction</h3>
          <p className="probability">
            {(mlPrediction.probability * 100).toFixed(0)}% chance of success
          </p>
          <p>{mlPrediction.message}</p>
          <p className="recommendation">{mlPrediction.recommendation}</p>
          <div className="confidence-bar">
            <div 
              className="confidence-fill" 
              style={{ width: `${mlPrediction.confidence * 100}%` }}
            />
          </div>
          <p className="confidence-label">
            Confidence: {(mlPrediction.confidence * 100).toFixed(0)}%
          </p>
        </Card>
      )}

      {/* Rest of home page */}
    </div>
  );
};
```

---

## üìä **Expected Results**

### **After 1 Month** (1,000 samples)
- ‚úÖ Basic ML models trained
- ‚úÖ 70-75% accuracy
- ‚úÖ Better than random guessing

### **After 3 Months** (5,000 samples)
- ‚úÖ Good ML models
- ‚úÖ 80-85% accuracy
- ‚úÖ Personalized predictions

### **After 6 Months** (10,000+ samples)
- ‚úÖ Excellent ML models
- ‚úÖ 85-90% accuracy
- ‚úÖ Highly personalized
- ‚úÖ Pattern recognition working

---

## üéØ **Success Metrics**

| Metric | Target | How to Measure |
|--------|--------|----------------|
| **Workout Success Accuracy** | 80%+ | Predicted vs Actual completion |
| **Recovery Time Accuracy** | ¬±0.5 days | Predicted vs Actual recovery |
| **Weight Progression Success** | 85%+ | Successful increases |
| **User Satisfaction** | 4.5/5 | User feedback ratings |

---

## üö® **Important Notes**

1. **Privacy**: All ML data is user-specific and private (RLS enabled)
2. **Fallback**: Always have rule-based fallback when ML fails
3. **Transparency**: Tell users when ML is being used
4. **Consent**: Get user permission to use their data for ML
5. **Testing**: A/B test ML vs rule-based before full rollout

---

## üìö **Resources**

- **scikit-learn**: https://scikit-learn.org/
- **TensorFlow.js**: https://www.tensorflow.org/js
- **ONNX**: https://onnx.ai/
- **Flask**: https://flask.palletsprojects.com/

---

## ‚úÖ **Summary**

**Files Created:**
- ‚úÖ `mlDataCollector.js` - Data collection
- ‚úÖ `20260118_ml_training_tables.sql` - Database schema
- ‚úÖ `train_models.py` - Python training pipeline
- ‚úÖ `mlInferenceService.js` - Prediction service

**Next Steps:**
1. Run database migration
2. Integrate data collection
3. Wait 3-6 months for data
4. Train models
5. Deploy and test

**Timeline:** 6 months from start to production ML! üöÄ
